{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9bf4c75",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5235b7",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55163fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "train_data = pd.read_csv(\"./data/train.csv\")\n",
    "test_data = pd.read_csv(\"./data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4b19e3",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f2aed3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape = (891, 12)\n",
      "Y_train.shape = (891,)\n",
      "X_test.shape = (418, 12)\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import preprocessing\n",
    "\n",
    "\n",
    "X_train, Y_train, X_test = preprocessing(train_data, test_data)\n",
    "\n",
    "print(\"X_train.shape =\", X_train.shape)\n",
    "print(\"Y_train.shape =\", Y_train.shape)\n",
    "print(\"X_test.shape =\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a76dd13",
   "metadata": {},
   "source": [
    "## Build A Simple Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1ab0f7",
   "metadata": {},
   "source": [
    "### Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3707e955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "class TitanicDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.Y is None:\n",
    "            return self.X[idx, :]\n",
    "        else:\n",
    "            return self.X[idx, :], self.Y[idx]\n",
    "\n",
    "X_train = torch.from_numpy(X_train)\n",
    "Y_train = torch.from_numpy(Y_train)\n",
    "X_test = torch.from_numpy(X_test)\n",
    "\n",
    "train_data = TitanicDataset(X_train, Y_train)\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c6203c",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9f4f8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=12, out_features=15, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=15, out_features=18, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=18, out_features=24, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=24, out_features=18, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=18, out_features=15, bias=True)\n",
      "    (9): ReLU()\n",
      "    (10): Linear(in_features=15, out_features=12, bias=True)\n",
      "    (11): ReLU()\n",
      "    (12): Linear(in_features=12, out_features=6, bias=True)\n",
      "    (13): ReLU()\n",
      "    (14): Linear(in_features=6, out_features=3, bias=True)\n",
      "    (15): ReLU()\n",
      "    (16): Linear(in_features=3, out_features=1, bias=True)\n",
      "  )\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "num_features = X_train.shape[1]\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(num_features, int(num_features * 1.25)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(num_features * 1.25), int(num_features * 1.5)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(num_features * 1.5), int(num_features * 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(num_features * 2), int(num_features * 1.5)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(num_features * 1.5), int(num_features * 1.25)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(num_features * 1.25), int(num_features * 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(num_features * 1), int(num_features * 0.5)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(num_features * 0.5), int(num_features * 0.25)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(num_features * 0.25), 1)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.linear_relu_stack(X)\n",
    "        Y_hat = self.sigmoid(X)\n",
    "        \n",
    "        return Y_hat\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb5ad35",
   "metadata": {},
   "source": [
    "### Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "271151bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af0c6d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.703206  [    0/  891]\n",
      "loss: 0.700588  [  256/  891]\n",
      "loss: 0.700584  [  512/  891]\n",
      "loss: 0.699867  [  369/  891]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.701249  [    0/  891]\n",
      "loss: 0.695804  [  256/  891]\n",
      "loss: 0.702886  [  512/  891]\n",
      "loss: 0.701152  [  369/  891]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.701379  [    0/  891]\n",
      "loss: 0.697153  [  256/  891]\n",
      "loss: 0.697744  [  512/  891]\n",
      "loss: 0.701843  [  369/  891]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.696667  [    0/  891]\n",
      "loss: 0.698499  [  256/  891]\n",
      "loss: 0.699524  [  512/  891]\n",
      "loss: 0.697881  [  369/  891]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.697766  [    0/  891]\n",
      "loss: 0.697798  [  256/  891]\n",
      "loss: 0.696377  [  512/  891]\n",
      "loss: 0.697195  [  369/  891]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.696228  [    0/  891]\n",
      "loss: 0.696139  [  256/  891]\n",
      "loss: 0.697150  [  512/  891]\n",
      "loss: 0.695445  [  369/  891]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.695092  [    0/  891]\n",
      "loss: 0.695333  [  256/  891]\n",
      "loss: 0.695719  [  512/  891]\n",
      "loss: 0.695843  [  369/  891]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.694731  [    0/  891]\n",
      "loss: 0.694598  [  256/  891]\n",
      "loss: 0.694662  [  512/  891]\n",
      "loss: 0.694282  [  369/  891]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.693832  [    0/  891]\n",
      "loss: 0.693681  [  256/  891]\n",
      "loss: 0.693668  [  512/  891]\n",
      "loss: 0.693649  [  369/  891]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.693191  [    0/  891]\n",
      "loss: 0.692959  [  256/  891]\n",
      "loss: 0.692872  [  512/  891]\n",
      "loss: 0.692325  [  369/  891]\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.692227  [    0/  891]\n",
      "loss: 0.691855  [  256/  891]\n",
      "loss: 0.692607  [  512/  891]\n",
      "loss: 0.692044  [  369/  891]\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.692345  [    0/  891]\n",
      "loss: 0.691625  [  256/  891]\n",
      "loss: 0.691409  [  512/  891]\n",
      "loss: 0.691327  [  369/  891]\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.691569  [    0/  891]\n",
      "loss: 0.691589  [  256/  891]\n",
      "loss: 0.691311  [  512/  891]\n",
      "loss: 0.690279  [  369/  891]\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.691756  [    0/  891]\n",
      "loss: 0.690709  [  256/  891]\n",
      "loss: 0.690042  [  512/  891]\n",
      "loss: 0.691401  [  369/  891]\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.690965  [    0/  891]\n",
      "loss: 0.690080  [  256/  891]\n",
      "loss: 0.690239  [  512/  891]\n",
      "loss: 0.691100  [  369/  891]\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.690025  [    0/  891]\n",
      "loss: 0.689504  [  256/  891]\n",
      "loss: 0.691301  [  512/  891]\n",
      "loss: 0.689172  [  369/  891]\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.689244  [    0/  891]\n",
      "loss: 0.689242  [  256/  891]\n",
      "loss: 0.689852  [  512/  891]\n",
      "loss: 0.691586  [  369/  891]\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.689577  [    0/  891]\n",
      "loss: 0.690079  [  256/  891]\n",
      "loss: 0.689865  [  512/  891]\n",
      "loss: 0.685913  [  369/  891]\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.689324  [    0/  891]\n",
      "loss: 0.688017  [  256/  891]\n",
      "loss: 0.688383  [  512/  891]\n",
      "loss: 0.691037  [  369/  891]\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.688931  [    0/  891]\n",
      "loss: 0.690288  [  256/  891]\n",
      "loss: 0.686974  [  512/  891]\n",
      "loss: 0.685671  [  369/  891]\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.686703  [    0/  891]\n",
      "loss: 0.687060  [  256/  891]\n",
      "loss: 0.689125  [  512/  891]\n",
      "loss: 0.687166  [  369/  891]\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.687092  [    0/  891]\n",
      "loss: 0.684812  [  256/  891]\n",
      "loss: 0.687687  [  512/  891]\n",
      "loss: 0.689610  [  369/  891]\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.686179  [    0/  891]\n",
      "loss: 0.686810  [  256/  891]\n",
      "loss: 0.685333  [  512/  891]\n",
      "loss: 0.685622  [  369/  891]\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.684927  [    0/  891]\n",
      "loss: 0.685715  [  256/  891]\n",
      "loss: 0.684862  [  512/  891]\n",
      "loss: 0.684240  [  369/  891]\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.683765  [    0/  891]\n",
      "loss: 0.684300  [  256/  891]\n",
      "loss: 0.683450  [  512/  891]\n",
      "loss: 0.682285  [  369/  891]\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.682718  [    0/  891]\n",
      "loss: 0.682743  [  256/  891]\n",
      "loss: 0.681022  [  512/  891]\n",
      "loss: 0.677921  [  369/  891]\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.680219  [    0/  891]\n",
      "loss: 0.681246  [  256/  891]\n",
      "loss: 0.676764  [  512/  891]\n",
      "loss: 0.674222  [  369/  891]\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.675953  [    0/  891]\n",
      "loss: 0.674635  [  256/  891]\n",
      "loss: 0.673690  [  512/  891]\n",
      "loss: 0.674018  [  369/  891]\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.670229  [    0/  891]\n",
      "loss: 0.670760  [  256/  891]\n",
      "loss: 0.667889  [  512/  891]\n",
      "loss: 0.667271  [  369/  891]\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.663303  [    0/  891]\n",
      "loss: 0.666726  [  256/  891]\n",
      "loss: 0.660793  [  512/  891]\n",
      "loss: 0.651211  [  369/  891]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.656963  [    0/  891]\n",
      "loss: 0.656151  [  256/  891]\n",
      "loss: 0.643876  [  512/  891]\n",
      "loss: 0.654030  [  369/  891]\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.647126  [    0/  891]\n",
      "loss: 0.646944  [  256/  891]\n",
      "loss: 0.630338  [  512/  891]\n",
      "loss: 0.632852  [  369/  891]\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.634872  [    0/  891]\n",
      "loss: 0.626823  [  256/  891]\n",
      "loss: 0.616990  [  512/  891]\n",
      "loss: 0.639119  [  369/  891]\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.624029  [    0/  891]\n",
      "loss: 0.607063  [  256/  891]\n",
      "loss: 0.610567  [  512/  891]\n",
      "loss: 0.635762  [  369/  891]\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.620284  [    0/  891]\n",
      "loss: 0.589563  [  256/  891]\n",
      "loss: 0.618335  [  512/  891]\n",
      "loss: 0.601196  [  369/  891]\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.609163  [    0/  891]\n",
      "loss: 0.600029  [  256/  891]\n",
      "loss: 0.589870  [  512/  891]\n",
      "loss: 0.603433  [  369/  891]\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.615234  [    0/  891]\n",
      "loss: 0.580227  [  256/  891]\n",
      "loss: 0.570407  [  512/  891]\n",
      "loss: 0.632948  [  369/  891]\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.566046  [    0/  891]\n",
      "loss: 0.572678  [  256/  891]\n",
      "loss: 0.610147  [  512/  891]\n",
      "loss: 0.632311  [  369/  891]\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.566025  [    0/  891]\n",
      "loss: 0.624729  [  256/  891]\n",
      "loss: 0.567584  [  512/  891]\n",
      "loss: 0.573087  [  369/  891]\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.558315  [    0/  891]\n",
      "loss: 0.605198  [  256/  891]\n",
      "loss: 0.568406  [  512/  891]\n",
      "loss: 0.595456  [  369/  891]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.float()\n",
    "        y = y.float()\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # Compute prediction error\n",
    "        pred = model(X).flatten()\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        loss, current = loss.item(), batch * len(X)\n",
    "        print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "epochs = 40\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0047d0",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "678c6494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, X_test):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_test = X_test.float()\n",
    "        X_test = X_test.to(device)\n",
    "        pred = model(X_test).numpy().flatten() >= 0.5\n",
    "        pred = pred.astype(int)\n",
    "    return pred\n",
    "\n",
    "Y_pred = test(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18e58ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ead41f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
